{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Spark Example\n",
    "\n",
    "First we need to add Spark repository and import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 artifact(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.SparkContext\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.SparkConf\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\"org.apache.spark\" % \"spark-core_2.11\" % \"1.6.0\")\n",
    "\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we configure a local SparkConf (as this docker image is build without Hadoop etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mconf\u001b[0m: \u001b[32mSparkConf\u001b[0m = org.apache.spark.SparkConf@3107591b\n",
       "\u001b[36msc\u001b[0m: \u001b[32mSparkContext\u001b[0m = org.apache.spark.SparkContext@13998bca"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val conf = new SparkConf()\n",
    "                .setMaster(\"local[*]\")\n",
    "                .setAppName(\"MonteCarloPi\")\n",
    "val sc = new SparkContext(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example utilizing parallel execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo estimate of pi is 3.1244\n",
      "The error in the estimate is -0.01719265358979305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcount\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m7811\u001b[0m\n",
       "\u001b[36mpiEstimate\u001b[0m: \u001b[32mDouble\u001b[0m = \u001b[32m3.1244\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val count = sc.parallelize(1 to 10000).map{ i =>\n",
    "  val x = Math.random\n",
    "  val y = Math.random\n",
    "  if (x*x + y*y < 1) 1 else 0\n",
    "}.reduce(_ + _)\n",
    "val piEstimate = 4.0 * count / 10000.0\n",
    "\n",
    "println(\"Monte Carlo estimate of pi is \" + piEstimate)\n",
    "println(\"The error in the estimate is \" + (piEstimate - Math.PI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
